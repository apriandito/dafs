---
title: "Machine Learning - Supervised"
author: "Muhammad Apriandito"
---

Di praktek kali ini kita akan belajar membuat model machine learning untuk memprediksi apakah seorang nasabah akan berlangganan Deposito Berjangka (Term Deposit) menggunakan Bank Marketing Dataset seperti yang sudah kita gunakan di modul-modul sebelumnya. Dataset bank marketing ini berisi informasi terkait Marketing Campaign sebuah Bank di Portugis. Tujuan dari Marketing Campaign ini yaitu untuk menawarkan deposito berjangka (Deposito Jangka Panjang) kepada para nasabah. 

## Load Package
Pada praktik-praktik sebelumnya, teman-teman sudah belajar berbagai Packages seperti `dplyr`, `readr`, `ggplot`. Package-Package tersebut merupakan bagian dari Package `tidyverse`. Package tidyverse ini merupakan sekumpulan Package-Package untuk melakukan proses data science, mulai dari mengimport data hingga melakukan visualisasi. Dengan me-load Package ```tidyverse``` kita secara otomatis juga akan mengaktifkan Package-Package yang ada didalamnya, termasuk `dplyr`, `readr`, `ggplot`. Untuk melihat Package apa saja yang termasuk di Package tidyverse, teman-teman dapat melihatnya di dokumentasi tidyverse. 

Selain Package `tidyverse`, kita juga memerlukan Package `tidymodels` untuk membantu membuat alur/workflow model machine learning Mari kita install dan load Package-Package tersebut terlebih dahulu. 

```{r}
# Install package
install.packages(c("tidyverse", 
                   "tidymodels", 
                   "discrim", 
                   "themis", 
                   "rpart.plot",
                   "randomForest",
                   "naivebayes"))
```

```{r}
# Load package
library(tidyverse)
library(tidymodels)
library(rpart)
library(rpart.plot)
library(themis)
library(discrim)
```

## Import Data
Sebelum memulai, mari kita import datanya terlebih dahulu. 

```{r}
# Import Data
df <- read_csv2("data/bank-marketing-fix.csv")
```

Setelah diimport, kita dapat melihat beberapa data pertama menggunakan fungsi ```head()``` , atau menggunakan fungsi ```glimpse()```

```{r}
# Meampilkan 5 baris pertama data
head(df)
```

```{r}
# menampilkan rangkuman data menggunakan fungsi glimpse()
glimpse(df)
```

Pada umumnya, setelah data diimport, tahapan selanjutnya yaitu EDA atau Exploratory Data Analysis. EDA bertujuan untuk mencari insight awal terkait data yang kita miliki. Namun, di praktik kali ini kita mengsumsikan bahwa data yang kita miliki sudah cukup baik untuk dimodelkan, dan kita sudah memahami data tersebut pada saat praktik-praktik sebelumnya.  

## Split Data
Sebelum dimodelkan, data harus dibagi menjadi dua yaitu data train untuk membuat model, dan data test untuk menguji performa model. Umumnya, data dibagi dengan proporsi: 70% train dan 30% test.

```{r}
# Set Seed
set.seed(1234)
```

```{r}
# Membagi data dengan proporsi 70:30
df_split <- initial_split(df, prop = 0.7)
df_split
```

```{r}
# Menampilkan data training
df_split %>%
  training() %>%
  glimpse()
```

## Membut Alur Pemrosesan Data
Setelah membagi data menjadi data training dan data testing, kita dapat mulai membuat alur pemrosesan data. Disini, kita akan menenetukan peran masing-masing variable, meliputi peran sebagai target yang diprediksi, dan yang berperan sebagai prediktor. Pada pemrosesan data ini kita juga dapat menambah proses lainnya untuk meningkatkan kualitas data seperti: mengisi nilai data yang kosong, normalisasi, down sampling, dan sebagainya. 

```{r}
# Membuat Recipe
df_recipe <- training(df_split) %>%
  recipe(y ~.) %>%
  step_downsample(y) %>%
  prep()

df_recipe
```

Untuk melihat hasil pemrosesan pada data traning, kita dapat menggunakan fungsi ```juice()```.

```{r}
# Mererapkan ke data training 
df_training <- juice(df_recipe)
glimpse(df_training)
```

Jika sudah sesuai, kita dapat menerapkan proses tersebut pada data testing menggunakan fungsi ```bake```.

```{r}
# Menerapkan ke data testing
df_testing <- df_recipe %>%
  bake(testing(df_split)) 
glimpse(df_testing)
```

## Menentukan Algoritma
Tahap selanjutnya adalah menetukan algoritma apa yang akan kita gunakan untuk melakukan prediksi klasifikasi. Di modul ini, kita akan menggunakan algoritma decision tree.

```{r}
# Menset model decision tree
dt <-  decision_tree() %>%
  set_engine("rpart") %>% 
  set_mode("classification") 
```

```{r}
rf <-  rand_forest(mode = "classification") %>%
    set_engine("randomForest")
```

```{r}
# Setting the Naive Bayes Model
nb <-  naive_Bayes() %>% 
  set_engine("naivebayes") %>% 
  translate()
```


## Membuat Workflow
Jika sudah menentukan alur pemrosesan data dan algoritma yang akan digunakan, kita dapat menyatukannya menjadi 1 workflow. 

```{r}
# Membuat Workflow
workflow_dt <- workflow() %>%
  add_model(dt) %>%
  add_recipe(df_recipe)
```

```{r}
# Membuat Workflow
workflow_rf <- workflow() %>%
  add_model(rf) %>%
  add_recipe(df_recipe)
```

```{r}
# Membuat Workflow
workflow_nb <- workflow() %>%
  add_model(nb) %>%
  add_recipe(df_recipe)
```

## Training dan Prediksi ke data set
Jika workflow sudah sesuai dan berhasil dibuat, kita dapat langsung melakukan proses training dan melakukan prediksi pada data testing.

```{r}
# Training Model dt
model_dt <- fit(workflow_dt, training(df_split))
```

```{r}
# Lihat Model dt
tree_fit <- model_dt %>% 
  pull_workflow_fit()
rpart.plot(tree_fit$fit,roundint=FALSE)
```


```{r}
model_rf <- fit(workflow_rf, training(df_split))
```


```{r}
# Training model nb
model_nb <- fit(workflow_nb, training(df_split))
```





##  Mengukur Performa Model
Tahapan terakhir yang dilakukan yaitu melakukan penilaian model. Penilaian ini digunakan untuk mengukur seberapa baik model kita dalam memprediksi dengan membandingkan nilai hasil prediksi dengan nilai yang sebenarnya. 

```{r}
# Menentukan metrik evaluasi untuk mengukur performa model
multi_metrics <- metric_set(accuracy, 
                            precision, 
                            recall, 
                            specificity, 
                            f_meas)
```

```{r}
# Melihat performa model decision tree
model_dt %>%
  predict(df_testing) %>%
  bind_cols(df_testing) %>%
  multi_metrics(truth = y, estimate = .pred_class)
```

```{r}
# Melihat performa model random forest
model_rf %>%
  predict(df_testing) %>%
  bind_cols(df_testing) %>%
  multi_metrics(truth = y, estimate = .pred_class)
```

```{r}
# Melihat performa model naive bayes
model_nb %>%
  predict(df_testing) %>%
  bind_cols(df_testing) %>%
  multi_metrics(truth = y, estimate = .pred_class)
```


Ternyata, model yang kita bangun memiki akurasi yang cukup baik, yaitu diatas 80%. Namun, tidak dengan nilai s

##  Mengaplikasikan Model ke Data Baru
Langkah akhir dari pembuatan sebuah model yaitu menggunakan model yang telah dibentuk untuk memprediksi data baru. Pada modul ini, kita memiliki 10 data nasabah baru yang belum diketahui apakah pelanggan tersebut akan memilih untuk berlanganan deposito berjangka atau tidak. Kita akan menggunakan model yang sudah kita buat untuk memprediksinya. 

Data yang akan diprediksi terletak pada directory "data/raw" dengan nama "bank-marketing_new.csv". 

```{r}
# Import data baru
df_new <- read_csv2("data/bank-marketing_new.csv")
head(df_new)
```

Dapat kita lihat bahwa belum ada kolom yang menyatakan bahwa pelanggan tersebut berlanggan deposito berjangka atu tidak. Untuk melakukan prediksi kita dapat langsung menggunakan fungsi ```predict``` ke data baru kita. 

```{r}
# Melakukan prediksi dan menyimpan nilai hasil prediksi
df_predicted <- predict(model_rf, df_new) %>%
  
  bind_cols(df_new) %>%
  write_csv("data/bank-marketing_predicted.csv")

# Menampilkan hasil prediksi
print(df_predicted)
```

dari 10 nasabah baru, ternyata ada 4 orang nasbah yang diprediksi akan berlangganan deposito berjangka, sedangkan 6 lainnya diprediksi tidak akan berlangganan deposito berjangka. 

```{r}
# Siapa yang akan berlangganan
df_subscribe <- df_predicted %>%
  filter(.pred_class == "yes")

print(df_subscribe)
```
